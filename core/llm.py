#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2026/1/30 11:32
# @Author  : wang ke
# @File    : llm.py
# @Software: PyCharm

from openai import OpenAI
from typing import List, Dict

from utils.time_decorator import timer_decorator
from utils.log import Log

logger = Log()

class LLM:
    """
    å¤§è¯­è¨€æ¨¡å‹å®¢æˆ·ç«¯å°è£…ç±»ã€‚
    """

    def __init__(self, model: str = None, apikey: str = None, baseurl: str = None, timeout: int = 80):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚
        """
        self.model = model

        if not all([self.model, apikey, baseurl]):
            raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚")

        self.client = OpenAI(api_key=apikey, base_url=baseurl, timeout=timeout)

    @timer_decorator
    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚
        """
        logger.info(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )

            # å¤„ç†æµå¼å“åº”
            logger.info("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)
            print()  # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            logger.error(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None